{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem\n",
    "#### Given\n",
    "\n",
    "| **Region** \t| **Temp (F)** \t| **Rainfall (mm)** \t| **Humidity (%)** \t| **Apple (ton)** \t| **Oranges (ton)** \t|\n",
    "|------------\t|--------------\t|-------------------\t|------------------\t|-----------------\t|-------------------\t|\n",
    "| Kanto      \t| 73           \t| 67                \t| 43               \t| 56              \t| 70                \t|\n",
    "| Johto      \t| 91           \t| 88                \t| 64               \t| 81              \t| 101               \t|\n",
    "| Hoenn      \t| 87           \t| 134               \t| 58               \t| 119             \t| 133               \t|\n",
    "| Sinnoh     \t| 102          \t| 43                \t| 37               \t| 22              \t| 37                \t|\n",
    "| Unova      \t| 69           \t| 96                \t| 70               \t| 103             \t| 119               \t|\n",
    "\n",
    "#### Task\n",
    "- Build a Regression model to predict apple and orange yield as\n",
    "\n",
    "```\n",
    "yield_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
    "yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution\n",
    "## 1. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([\n",
    "    [73, 67, 43], \n",
    "    [91, 88, 64], \n",
    "    [87, 134, 58], \n",
    "    [102, 43, 37], \n",
    "    [69, 96, 70]], dtype='float32')\n",
    "\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([\n",
    "    [56, 70], \n",
    "    [81, 101], \n",
    "    [119, 133], \n",
    "    [22, 37], \n",
    "    [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Convert inputs and targets to tensors\n",
    "X = torch.from_numpy(inputs)\n",
    "y = torch.from_numpy(targets)\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Regression from scratch\n",
    "#### 2.1 Model\n",
    "- Define model: $y = X*W^T + b$\n",
    "\n",
    "- X = Input data\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "73 & 67 & 43 \\\\\n",
    "91 & 88 & 64 \\\\\n",
    "... & ... & ... \\\\\n",
    "69 & 96 & 70\n",
    "\\end{bmatrix}$\n",
    "\n",
    "- $W^T$: W = (2,3) tensor\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "w_{11} & w_{21} \\\\\n",
    "w_{12} & w_{22} \\\\\n",
    "w_{13} & w_{23} \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "- b = (2,) tensor\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "b_1 & b_2 \\\\\n",
    "b_1 & b_2 \\\\\n",
    "... & ... \\\\\n",
    "b_1 & b_2 \\\\\n",
    "\\end{bmatrix}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(t1, t2):\n",
    "    '''MSE Loss'''\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff * diff) / diff.numel()\n",
    "\n",
    "def fit(X,y):\n",
    "    # Init W, b\n",
    "    W = torch.randn(2, 3, requires_grad=True)\n",
    "    b = torch.randn(2, requires_grad=True)\n",
    "\n",
    "    # Train for 1000 epochs\n",
    "    for i in range(1000):\n",
    "        # Forward: Model\n",
    "        y_ = X @ W.t() + b\n",
    "        loss = mse(y_, y)\n",
    "        \n",
    "        # Backprop - Grad descent: Optimizer\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            # Update W,b\n",
    "            W -= W.grad * 1e-5\n",
    "            b -= b.grad * 1e-5\n",
    "\n",
    "            # Reset Grad (=0)\n",
    "            W.grad.zero_()\n",
    "            b.grad.zero_()\n",
    "\n",
    "        # Print the progress\n",
    "        if (i+1)%100==0:\n",
    "            print(\"Epoch {}: loss = {}\".format(str(i+1), loss))\n",
    "\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: loss = 540.4302978515625\n",
      "Epoch 200: loss = 212.7572784423828\n",
      "Epoch 300: loss = 110.46502685546875\n",
      "Epoch 400: loss = 73.1790542602539\n",
      "Epoch 500: loss = 55.596466064453125\n",
      "Epoch 600: loss = 44.755897521972656\n",
      "Epoch 700: loss = 36.813533782958984\n",
      "Epoch 800: loss = 30.51938819885254\n",
      "Epoch 900: loss = 25.38027572631836\n",
      "Epoch 1000: loss = 21.14005470275879\n"
     ]
    }
   ],
   "source": [
    "# Train and get final model\n",
    "W, b = fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 57.4870,  70.9981],\n",
      "        [ 79.6267,  96.8389],\n",
      "        [124.0437, 140.5685],\n",
      "        [ 22.7137,  39.2817],\n",
      "        [ 96.4704, 111.4148]], grad_fn=<AddBackward0>)\n",
      "tensor(21.1016, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Suppose test set = train set\n",
    "X_test = X\n",
    "y_test = y\n",
    "\n",
    "# Predict and calculate loss\n",
    "y_test_ = X_test @ W.t() + b\n",
    "loss = mse(y_test_, y_test)\n",
    "\n",
    "print(y_test_)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear Regression by PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Add X, y as torch dataset\n",
    "train_ds = TensorDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1650,  0.2156,  0.5539],\n",
      "        [ 0.3330, -0.3646, -0.3487]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4029,  0.2775], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define model\n",
    "lr_model = nn.Linear(3, 2)\n",
    "\n",
    "# Check model params\n",
    "print(lr_model.weight)\n",
    "print(lr_model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Loss function: pytorch MSE\n",
    "mse_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer: SGD\n",
    "sgd_opt = torch.optim.SGD(lr_model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "\n",
    "    # Repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train with batches of data\n",
    "        for Xb,yb in train_dl:\n",
    "            \n",
    "            # 1. Generate predictions\n",
    "            yb_ = model(Xb)\n",
    "            \n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(yb_, yb)\n",
    "            \n",
    "            # 3. Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # 4. Update parameters using gradients\n",
    "            opt.step()\n",
    "            \n",
    "            # 5. Reset the gradients to zero\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        # Print the progress\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 254.4128\n",
      "Epoch [200/1000], Loss: 87.7300\n",
      "Epoch [300/1000], Loss: 38.2366\n",
      "Epoch [400/1000], Loss: 22.0911\n",
      "Epoch [500/1000], Loss: 15.6879\n",
      "Epoch [600/1000], Loss: 12.3376\n",
      "Epoch [700/1000], Loss: 10.1086\n",
      "Epoch [800/1000], Loss: 8.4138\n",
      "Epoch [900/1000], Loss: 7.0511\n",
      "Epoch [1000/1000], Loss: 5.9328\n"
     ]
    }
   ],
   "source": [
    "fit(\n",
    "    num_epochs=1000,\n",
    "    model=lr_model,\n",
    "    loss_fn=mse_fn,\n",
    "    opt=sgd_opt,\n",
    "    train_dl=train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 57.1149,  70.6505],\n",
      "        [ 82.2059,  98.3332],\n",
      "        [118.7748, 137.7253],\n",
      "        [ 21.1884,  38.4705],\n",
      "        [101.7760, 114.2781]], grad_fn=<AddmmBackward>)\n",
      "tensor(5.9226, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Suppose test set = train set\n",
    "X_test = X\n",
    "y_test = y\n",
    "\n",
    "# Predict and calculate loss\n",
    "y_test_ = lr_model(X_test)\n",
    "loss = mse_fn(y_test_, y_test)\n",
    "\n",
    "print(y_test_)\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
