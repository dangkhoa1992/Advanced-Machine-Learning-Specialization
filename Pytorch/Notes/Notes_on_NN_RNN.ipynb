{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM cell\n",
    "\n",
    "<img src=\"./assets/1.png\" width=\"500\"/>\n",
    "\n",
    "- Input:\n",
    "    - $c_{t-1}, h_{t-1}$: Input cell, hidden\n",
    "    - $x_t$: Input data\n",
    "\n",
    "\n",
    "#### Forget gate\n",
    "- f = 0: completely forget memories from $c_{t-1}$\n",
    "- f = 1: completely includes memories from $c_{t-1}$\n",
    "\n",
    "$$ f = \\sigma(W_{if}x_t + b_{if} + W_{hf}h_{t-1} + b_{hf})$$\n",
    "\n",
    "\n",
    "#### Input gate\n",
    "- Determining how important the (transformed) new external input ($x_t$) is.\n",
    "\n",
    "\n",
    "\n",
    "$$i = \\sigma(W_{ii}x_t + b_{ii} + W_{hi}h_{t-1} + b_{hi})$$\n",
    "\n",
    "\n",
    "#### Cell gate\n",
    "- non-linear transformation of the new external input $x_t$\n",
    "\n",
    "$$g = tanh(W_{ig}x_t + b_{ig} + W_{hg}h_{t-1} + b_{hg})$$\n",
    "\n",
    "\n",
    "#### output gate\n",
    "- Controls how much of the new cell state $c_t$ should go to the output (and the hidden state $h_t$)\n",
    "\n",
    "$$ o = \\sigma(W_{io}x_t + b_{io} + W_{ho}h_{t-1} + b_{ho})$$\n",
    "\n",
    "\n",
    "- Outputs\n",
    "    + $c_t = f*c + i*g$\n",
    "    + $h_t = o*tanh(c_t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "<img src=\"./assets/2.png\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 10\n",
    "HIDDEN_DIM = 20\n",
    "\n",
    "rnn = nn.LSTMCell(\n",
    "    input_size=INPUT_DIM,\n",
    "    hidden_size=HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 6\n",
    "X = torch.randn(T, INPUT_DIM)\n",
    "h = torch.randn(1, HIDDEN_DIM)\n",
    "c = torch.randn(1, HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 20])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CELL = 3\n",
    "\n",
    "outs = torch.zeros(NUM_CELL, 1, HIDDEN_DIM)\n",
    "for t in range(NUM_CELL):\n",
    "    x_t = X[t].unsqueeze(0)\n",
    "    h, c = rnn(x_t, (h, c))\n",
    "    outs[t] = h\n",
    "\n",
    "outs.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM layers\n",
    "`batch_first=True`: Give batch_size at dim=0 in output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 258\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "X = torch.rand(BATCH_SIZE, 192, INPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "\n",
    "rnn = nn.LSTM(\n",
    "    input_size=INPUT_DIM,\n",
    "    hidden_size=HID_DIM,\n",
    "    num_layers=N_LAYERS,\n",
    "    batch_first=True,\n",
    "    dropout=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feed with h_0, c_0 rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 192, 512])\n",
      "torch.Size([2, 64, 512])\n",
      "torch.Size([2, 64, 512])\n"
     ]
    }
   ],
   "source": [
    "out, (hidden, cell) = rnn(X)\n",
    "\n",
    "print(out.size())\n",
    "print(hidden.size())\n",
    "print(cell.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feed with initialized h_0, c_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 192, 512])\n",
      "torch.Size([2, 64, 512])\n",
      "torch.Size([2, 64, 512])\n"
     ]
    }
   ],
   "source": [
    "h_0 = torch.zeros(N_LAYERS, BATCH_SIZE, HID_DIM).float()\n",
    "c_0 = torch.zeros(N_LAYERS, BATCH_SIZE, HID_DIM).float()\n",
    "\n",
    "out, (hidden, cell) = rnn(X, (h_0, c_0))\n",
    "\n",
    "print(out.size())\n",
    "print(hidden.size())\n",
    "print(cell.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bi-LSTM layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 258\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "X = torch.rand(BATCH_SIZE, 192, INPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "\n",
    "bi_rnn = nn.LSTM(\n",
    "    input_size=INPUT_DIM,\n",
    "    hidden_size=HID_DIM,\n",
    "    num_layers=N_LAYERS,\n",
    "    batch_first=True,\n",
    "    bidirectional=True,\n",
    "    dropout=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feed with h_0, c_0 rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 192, 1024])\n",
      "torch.Size([4, 64, 512])\n",
      "torch.Size([4, 64, 512])\n"
     ]
    }
   ],
   "source": [
    "out, (hidden, cell) = bi_rnn(X)\n",
    "\n",
    "print(out.size())\n",
    "print(hidden.size())\n",
    "print(cell.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feed with initialized h_0, c_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 192, 1024])\n",
      "torch.Size([4, 64, 512])\n",
      "torch.Size([4, 64, 512])\n"
     ]
    }
   ],
   "source": [
    "h_0 = torch.zeros(2*N_LAYERS, BATCH_SIZE, HID_DIM).float()\n",
    "c_0 = torch.zeros(2*N_LAYERS, BATCH_SIZE, HID_DIM).float()\n",
    "\n",
    "out, (hidden, cell) = bi_rnn(X, (h_0, c_0))\n",
    "\n",
    "print(out.size())\n",
    "print(hidden.size())\n",
    "print(cell.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
