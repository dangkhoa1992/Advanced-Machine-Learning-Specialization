{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear transformations of random variables\n",
    "- We study a system of random variables where 2 random variables X and Y can interact with each other\n",
    "\n",
    "## 1.1 System of random variables\n",
    "- X,Y must have the same set of outcomes\n",
    "    - $\\Omega$: set of outcomes\n",
    "    - $P(\\omega)$: probability of outcome $\\omega \\in \\Omega$\n",
    "    - Random variable $X: \\Omega \\to R$\n",
    "    - Random variable $Y: \\Omega \\to R$\n",
    "- We define $(X, Y)$: the system of random variables\n",
    "\n",
    "## 1.2 Transformations of random variables\n",
    "- Let define X ass\n",
    "\n",
    "| **P** | 0.2 | 0.5 | 0.3 |\n",
    "|------------|-----|-----|-----|\n",
    "| **X**      | -1  | 3   | 4   |\n",
    "\n",
    "\n",
    "- X can transform to Y by\n",
    "\n",
    "#### Y = X + c, which `c = constant`\n",
    "- Example `c = 2`\n",
    "\n",
    "| **P**    | 0.2 | 0.5 | 0.3 |\n",
    "|---------------|-----|-----|-----|\n",
    "| **X**         | -1  | 3   | 4   |\n",
    "| **Y = X + 2** | 1   | 5   | 6   |\n",
    "\n",
    "#### Y = cX, which `c = constant`\n",
    "- Example `c = 2`\n",
    "\n",
    "| **P**    | 0.2 | 0.5 | 0.3 |\n",
    "|---------------|-----|-----|-----|\n",
    "| **X**         | -1  | 3   | 4   |\n",
    "| **Y = 2X** | -2   | 6  | 8   |\n",
    "\n",
    "#### Combine $Y = c_1X + c_2$, which `c1,c2 = constant`\n",
    "- Example `c = 2`\n",
    "\n",
    "| **P**    | 0.2 | 0.5 | 0.3 |\n",
    "|---------------|-----|-----|-----|\n",
    "| **X**         | -1  | 3   | 4   |\n",
    "| **Y = 2X+1** | -1   | 7  | 9   |\n",
    "\n",
    "- **Notes**: Only values are shifted, p does not changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Symmetric distributions\n",
    "\n",
    "- A symmetric distribution has the following PMF\n",
    "\n",
    "<img src=\"assets/8.png\" width=\"450\"/>\n",
    "\n",
    "#### Properties\n",
    "- $E(X) = x_0$\n",
    "- $E(X- x_0) = 0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Functions of random variables\n",
    "- We define a function `f` apply to random variable `X` to become `Z`\n",
    "    + $Z = f(X)$\n",
    "- X,Y,Z must have the same set of outcomes\n",
    "    - $\\Omega$: set of outcomes\n",
    "    - $P(\\omega)$: probability of outcome $\\omega \\in \\Omega$\n",
    "    - Random variable $X: \\Omega \\to R$\n",
    "    - Random variable $Z: \\Omega \\to R$\n",
    "- Properties \n",
    "    + Only Z values are shifted, p does not changed\n",
    "\n",
    "## 3.1 PMF\n",
    "\n",
    "| **P(X=x)** | $p_1$    | $p_2$    | ... | $p_n$    |\n",
    "|------------|----------|----------|-----|----------|\n",
    "| **X**      | $x_1$    | $x_2$    | ... | $x_n$    |\n",
    "| $Z = f(X)$ | $f(x_1)$ | $f(x_2)$ | ... | $f(x_n)$ |\n",
    "\n",
    "## 3.2 Expected value\n",
    "- $E(Z) = E[f(X)]$\n",
    "\n",
    "- Let $c, c_1, c_2$ = constant; X,Y,Z = random variables\n",
    "    - $E(Z = c) = c$\n",
    "    - $E(Z = X + c) = E(X) + c$\n",
    "    - $E(Z = cX) = cE(X)$\n",
    "    - $E(Z = c_1X + c_2) = c_1E(X) + c_2$\n",
    "    - $E(Z = X + Y) = E(X) + E(Y)$\n",
    "    - $E(Z = XY) = \\sum\\limits_i^m \\sum\\limits_j^n x_i y_j P(X=x_i \\cap Y=y_j)$\n",
    "    - $E(Z = X*Y) = E(X)E(Y)$, Only If `X and Y are independent`, See `6. Independent random variables`\n",
    "    - $E[Z = E(X)] = E(X)$\n",
    "    - $E[Z = XE(Y)] = E(X)E(Y)$\n",
    "    \n",
    "## 3.3 Variance\n",
    "- Let $c, c_1, c_2$ = constant; X,Y,Z = random variables\n",
    "    - $Var(Z = c) = 0$\n",
    "    - $Var(Z = X + c) = Var(X)$\n",
    "    - $Var(Z=cX) = c^2 Var(X)$\n",
    "    - $Var(Z=c_1X + c_2) = c_1^2 Var(X)$\n",
    "    - $Var(Z = X + Y) = Var(X) + Var(Y) + 2 cov(X,Y)$, See `7. Covariance`\n",
    "    - $Var(Z = X + Y) = Var(X) + Var(Y)$, Only If `X and Y are independent`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Joint probability distribution\n",
    "## 4.1 Example\n",
    "- Toss a fair coin 2 times\n",
    "- Define a random variable X\n",
    "\n",
    "$$X = \\begin{cases}\n",
    "1, \\text{ if 1st tossing is head} \\\\\n",
    "0, \\text{ otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "- Define random variable Y: $Y = 1 - X$\n",
    "- Define random variable Z:\n",
    "\n",
    "$$Z = \\begin{cases}\n",
    "1, \\text{ if 2nd tossing is head} \\\\\n",
    "0, \\text{ otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "#### PMFs\n",
    "- X\n",
    "\n",
    "| $\\omega$   | {HH,HT} | {TH,TT} |\n",
    "|------------|---------|---------|\n",
    "| **P(X=x)** | 0.5     | 0.5     |\n",
    "| **X**      | 1       | 0       |\n",
    "\n",
    "- Y\n",
    "\n",
    "| $\\omega$   | {TH,TT} | {HH,HT} |\n",
    "|------------|---------|---------|\n",
    "| **P(Y=y)** | 0.5     | 0.5     |\n",
    "| **Y**      | 1       | 0       |\n",
    "\n",
    "- Z\n",
    "\n",
    "| $\\omega$   | {HH,TH} | {TT,HT} |\n",
    "|------------|---------|---------|\n",
    "| **P(Z=z)** | 0.5     | 0.5     |\n",
    "| **Z**      | 1       | 0       |\n",
    "\n",
    "#### Analyze\n",
    "- X,Y,Z have the same PMF but\n",
    "- If we check\n",
    "    + $P(X=0 \\cap Y=0) =0$\n",
    "    + $P(X=0 \\cap Z=0) = P({TT}) = 0.25$\n",
    "- We need a new **definition** beside PMF $\\to$ `Joint probability distribution`\n",
    "\n",
    "## 4.2 Definition\n",
    "- Let X,Y: random variables\n",
    "    + suppose $X = \\{x_1, x_2, \\dots, x_n\\}$\n",
    "    + suppose $Y = \\{y_1, y_2, \\dots, y_n\\}$\n",
    "\n",
    "- joint distribution of X and Y is **a matrix** of $p_{ij}$, which\n",
    "    + $p_{ij} = P(X = x_i \\cap Y = y_j)$\n",
    "    \n",
    "| Y \\ X     | $X = x_1$             | $X = x_2$             | $\\dots$ | $X = x_m$             |\n",
    "|-----------|-----------------------|-----------------------|---------|-----------------------|\n",
    "| $Y = y_1$ | $P(X=x_1 \\cap Y=y_1)$ | $P(X=x_2 \\cap Y=y_1)$ | $\\dots$ | $P(X=x_m \\cap Y=y_1)$ |\n",
    "| $Y = y_2$ | $P(X=x_1 \\cap Y=y_2)$ | $P(X=x_2 \\cap Y=y_2)$ | $\\dots$ | $P(X=x_m \\cap Y=y_2)$ |\n",
    "| $\\dots$   | $\\dots$               | $\\dots$               | $\\dots$ | $\\dots$               |\n",
    "| $Y = y_n$ | $P(X=x_1 \\cap Y=y_n)$ | $P(X=x_2 \\cap Y=y_n)$ | $\\dots$ | $P(X=x_m \\cap Y=y_n)$ |\n",
    "\n",
    "\n",
    "- Properties\n",
    "    + $p_{ij} \\geq 0$\n",
    "    + $\\sum\\limits_{i=1}^m\\sum\\limits_{j=1}^np_{ij} = 1$\n",
    "    \n",
    "\n",
    "## 4.3 Example: Build `joint probability distribution` (Joint PMF) table for Example 4.1\n",
    "- X and Y\n",
    "    + $P(X=0 \\cap Y=0) = 0$\n",
    "    + $P(X=1 \\cap Y=0) = P(\\{HH,HT\\}) = \\frac{1}{2}$\n",
    "    + $P(X=0 \\cap Y=1) = P(\\{TH,TT\\}) = \\frac{1}{2}$\n",
    "    + $P(X=1 \\cap Y=1) = 0$\n",
    "\n",
    "| Y \\ X | **0** | **1** |\n",
    "|-------|-------|-------|\n",
    "| **0** | 0     | 0.5   |\n",
    "| **1** | 0.5   | 0     |\n",
    "\n",
    "\n",
    "- X and Z\n",
    "    + $P(X=0 \\cap Z=0) = P(\\{TT\\}) = \\frac{1}{4}$\n",
    "    + $P(X=1 \\cap Z=0) = P(\\{HT\\}) = \\frac{1}{4}$\n",
    "    + $P(X=0 \\cap Z=1) = P(\\{TH\\}) = \\frac{1}{4}$\n",
    "    + $P(X=1 \\cap Z=1) = P(\\{HH\\}) = \\frac{1}{4}$\n",
    "\n",
    "| Z \\ X | **0** | **1** |\n",
    "|-------|-------|-------|\n",
    "| **0** | 0.25  | 0.25  |\n",
    "| **1** | 0.25  | 0.25  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Marginal distribution\n",
    "- If we are give a `joint probability distribution` table of X and Y \n",
    "    - And, we only interested in 1 random variable\n",
    "- Given joint probability distribution table $\\to$ find PMF of X and Y\n",
    "\n",
    "## 5.1 Marginal distribution\n",
    "- If 2 random variable X, Y have the joint distribution as\n",
    "    + $p_{ij} = P(X = x_i \\cap Y = y_j)$\n",
    "\n",
    "- We can calculate marginal distribution of X (**a vector**) as\n",
    "    + $P(X=x_i) = p_{i1} + p_{i2} + \\dots + p_{in} = \\sum\\limits_{j=1}^n p_{ij}$\n",
    "\n",
    "- We can calculate marginal distribution of Y (**a vector**) as\n",
    "    + $P(Y=y_j) = p_{1j} + p_{2j} + \\dots + p_{mj} = \\sum\\limits_{i=1}^m p_{ij}$\n",
    "\n",
    "## 5.2 Example \n",
    "- Give the  joint PMF of 2 random variables X,Y as\n",
    "\n",
    "| X \\ Y     | **Y = 0** | **Y = 1** | **Y = 2** |\n",
    "|-----------|-----------|-----------|-----------|\n",
    "| **X = 0** | 1/4       | 1/6       | 1/12      |\n",
    "| **X = 1** | 1/16      | 1/8       | 5/16      |\n",
    "\n",
    "- Find PMF of X and Y\n",
    "\n",
    "#### Solve\n",
    "\n",
    "| X \\ Y        | **Y = 0** | **Y = 1** | **Y = 2** | $P(X = x_j)$ |\n",
    "|--------------|-----------|-----------|-----------|--------------|\n",
    "| **X = 0**    | 1/4       | 1/6       | 1/12      | 1/2          |\n",
    "| **X = 1**    | 1/16      | 1/8       | 5/16      | 1/2          |\n",
    "| $P(Y = y_i)$ | 5/16      | 7/24      | 19/48     |              |\n",
    "\n",
    "## 5.3 Exercises\n",
    "\n",
    "- Give a  joint distribution table of 2 random variables X,Y as\n",
    "\n",
    "| X \\ Y     | **Y = 0** | **Y = 1** | **Y = 2** |\n",
    "|-----------|-----------|-----------|-----------|\n",
    "| **X = 0** | 1/4       | 1/6       | 1/12      |\n",
    "| **X = 1** | 1/16      | 1/8       | 5/16      |\n",
    "\n",
    "\n",
    "#### Find $P( X=1 \\cap Y>0)$\n",
    "- $P( X=1 \\cap Y>0) = P( X=1 \\cap Y=1) + P( X=1 \\cap Y=2) = \\frac{1}{8} + \\frac{5}{16} = \\frac{7}{16}$\n",
    "\n",
    "#### Find $P( Y=2\\ |\\ X = 1)$\n",
    "\n",
    "- $P( Y=2\\ |\\ X = 1) = \\frac{P(Y=2 \\cap X=1)}{P(X=1)} = \\frac{5/16}{1/16 + 1/8 + 5/16} = \\frac{5}{8}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Independent random variables\n",
    "- Consider of a system of variable X and Y, defined on the same probability space\n",
    "- If we know something about X then we can have some new information about Y if X,Y are not independent\n",
    "\n",
    "## 6.1 Independence and Information inference\n",
    "- Let X,Y: random variables\n",
    "    + suppose $X = \\{x_1, x_2, \\dots, x_n\\}$\n",
    "    + suppose $Y = \\{y_1, y_2, \\dots, y_n\\}$\n",
    "\n",
    "- We have $P(Y = y_j | X = x_i)$ meaning: If $X = x_i$ occurs giving new information about Y\n",
    "- X and Y are Independent if\n",
    "    + $P(Y = y_j\\ |\\ X = x_i ) = P(Y = y_j)$, $\\forall i \\in [1,m]$, $\\forall j \\in [1,n]$ \n",
    "    + Or $P(X=x_i \\cap Y = y_j ) = P(X = x_i)P(Y = y_j)$, $\\forall i \\in [1,m]$, $\\forall j \\in [1,n]$ \n",
    "\n",
    "## 6.2 Example: Independence\n",
    "- Give the joint PMF of 2 random variables X,Z as\n",
    "\n",
    "| **Z\\X** | **X=0** | **X=1** |\n",
    "|---------|---------|---------|\n",
    "| **Z=0** | 0.25    | 0.25    |\n",
    "| **Z=1** | 0.25    | 0.25    |\n",
    "\n",
    "- Check Independency\n",
    "\n",
    "#### Solve\n",
    "\n",
    "- Calculate PMF of X and Z\n",
    "\n",
    "| **Z\\X**    | **X=0** | **X=1** | $P(Z=z_j)$ |\n",
    "|------------|---------|---------|------------|\n",
    "| **Z=0**    | 0.25    | 0.25    | 0.5        |\n",
    "| **Z=1**    | 0.25    | 0.25    | 0.5        |\n",
    "| $P(X=x_i)$ | 0.5     | 0.5     |            |\n",
    "\n",
    "- Check Independence\n",
    "    + $P(X=0 \\cap Z = 0 ) = P(X=0)P(Z=0) = 0.5*0.5 = 0.25$\n",
    "    + $P(X=0 \\cap Z = 1 ) = P(X=0)P(Z=1) = 0.5*0.5 = 0.25$\n",
    "    + $P(X=1 \\cap Z = 0 ) = P(X=1)P(Z=0) = 0.5*0.5 = 0.25$\n",
    "    + $P(X=1 \\cap Z = 1 ) = P(X=1)P(Z=1) = 0.5*0.5 = 0.25$\n",
    "- Conclusion: `X and Z are Independent`\n",
    "    + No info can be infered to Z if we know X\n",
    "\n",
    "## 6.3 Example: Non-Independence\n",
    "- Toss a fair coin 3 times. Let random variables\n",
    "    + X: Number of heads for 1st and 2nd toss\n",
    "    + Y: Number of heads for 2nd and 3rd toss\n",
    "\n",
    "- Check Independency\n",
    "\n",
    "#### Solve\n",
    "- Construct Joint PMF Table\n",
    "\n",
    "| Y\\X          | **X=0** | **X=1** | **X=2** | $P(Y = y_j)$ |\n",
    "|--------------|---------|---------|---------|--------------|\n",
    "| **Y=0**      | 1/8     | 1/8     | 0       | 1/4          |\n",
    "| **Y=1**      | 1/8     | 1/4     | 1/8     | 1/2          |\n",
    "| **Y=2**      | 0       | 1/8     | 1/8     | 1/4          |\n",
    "| $P(X = x_i)$ | 1/4     | 1/2     | 1/4     |              |\n",
    "\n",
    "- Exist: $P(X=0 \\cap Y=0 ) = 1/8 \\neq P(X=0)P(Y=0) = 1/4 * 1/4 = 1/16$\n",
    "- Conclusion: `X and Y are not Independent`\n",
    "    + Information can be infered. Eg:\n",
    "        + if X = 0 then Y must $\\neq$ 2\n",
    "        + if X = 0 then Y can be `0` or `1`\n",
    "\n",
    "## 6.4 Example: Completely Dependent\n",
    "- Roll a fair dice. Let random variables\n",
    "    + X: the number on the dice\n",
    "    + Y: = 0 if X is even, = 1 if X is odd\n",
    "- Check Independency\n",
    "\n",
    "#### Solve\n",
    "- Construct Joint PMF Table\n",
    "\n",
    "| Y\\X          | **X=1** | **X=2** | **X=3** | **X=4** | **X=5** | **X=6** | $P(Y = y_j)$ |\n",
    "|--------------|---------|---------|---------|---------|---------|---------|--------------|\n",
    "| **Y=0**      | 0       | 1/6     | 0       | 1/6     | 0       | 1/6     | 1/2          |\n",
    "| **Y=1**      | 1/6     | 0       | 1/6     | 0       | 1/6     | 0       | 1/2          |\n",
    "| $P(X = x_i)$ | 1/6     | 1/6     | 1/6     | 1/6     | 1/6     | 1/6     |              |\n",
    "\n",
    "- Exist: $P(X=1 \\cap Y=0 ) = 0 \\neq P(X=1)P(Y=0) = 1/6 * 1/2 = 1/12$\n",
    "- Conclusion: `X and Y are not Independent`\n",
    "    + Information of Y can be infered completely if we know X. Eg\n",
    "        + If X = 1, Y = 1\n",
    "        + If X = 2, Y = 0\n",
    "        + ...\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Covariance\n",
    "\n",
    "- Covariance measures the relation between 2 random variables X and Y\n",
    "- It is strongly related to dependence/Independence between X and Y\n",
    "\n",
    "## 7.1 Definition\n",
    "\n",
    "- Define Covariance of X and Y as $cov(X, Y) = E [ (X- E(X)) (Y - E(Y))    ]$\n",
    "\n",
    "$$\\begin{split}\n",
    "cov(X,Y) &= E [ (X- E(X)) (Y - E(Y))    ]  \\\\\n",
    "    &= E [XY -XE(Y) -YE(X) + E(X)E(Y)] \\\\\n",
    "    &= E(XY) - E(X)E(Y) -E(X)E(Y) + E(X)E(Y) \\\\\n",
    "    &= E(XY) - E(X)E(Y)\n",
    "\\end{split}$$\n",
    "\n",
    "\n",
    "\n",
    "## 7.2 Var(X + Y)\n",
    "\n",
    "$$\\begin{split}\n",
    "Var(X + Y) &= E [ (X + Y - E(X+Y))^2 ] \\\\\n",
    "        &= E [ (X-E(X) + Y-E(Y))^2 ] \\\\\n",
    "        &= E[(X-E(X))^2] + E[(Y-E(Y))^2] + 2 E[(X-E(X))(Y - E(Y))] \\\\\n",
    "        &= Var(X) + Var(Y) + 2 cov(X,Y)\n",
    "\\end{split}$$\n",
    "\n",
    "- We have cov(X,Y) represent by Var(X + Y) as (rarely use)\n",
    "\n",
    "$$cov(X,Y) = \\frac{1}{2} \\left[ Var(X + Y) - Var(X) - Var(Y) \\right]$$\n",
    "\n",
    "## 7.3 Properties\n",
    "- If `X and Y are independent` then `cov(X,Y) = 0`, **Note**: the inverse is not true\n",
    "\n",
    "- Let $c, c_1, c_2$ = constant; X,Y = random variables\n",
    "    - $cov(X,Y) = cov(Y,X)$\n",
    "    - $cov(X,X) = Var(X)$\n",
    "    - $cov(X+c, Y) = cov(X,Y)$\n",
    "    - $cov(cX, Y) = c*cov(X,Y)$\n",
    "    - $cov(X,\\ c_1X + c_2) = c_1*cov(X,X) = c_1Var(X)$\n",
    "\n",
    "\n",
    "## 7.4 Exercise 1\n",
    "- Calculate Variance of `Binomial random variable`\n",
    "- **Note**: Binomial random variable = $\\sum$ n independent Bernoulli random variables. Given  Bernoulli PMF as\n",
    "\n",
    "| **X**      | **X=1** | **X=0** |\n",
    "|------------|---------|---------|\n",
    "| **P(X=x)** | p       | 1-p     |\n",
    "\n",
    "#### Solve\n",
    "- Define\n",
    "    + $X$: Binomial random variable\n",
    "    + $X_i$, $i \\in [1,n]$:  Bernoulli random variables\n",
    "\n",
    "\n",
    "- Expected value of Bernoulli random variables\n",
    "    + $E(X_i) = p$\n",
    "\n",
    "\n",
    "- Calc $(X_i - E(X_i))^2$\n",
    "\n",
    "| $X_i$         | $X_i = 1$    | $X_i = 0$              |\n",
    "|----------------|------------|----------------------|\n",
    "| $P(X_i=x)$     | p          | 1-p                  |\n",
    "| $(X_i - E(X_i))^2$ | $(1-p)^2$ | $(0-p)^2  = p^2$ |\n",
    "\n",
    "\n",
    "- Variance of Binomial experiments\n",
    "\n",
    "$$\\begin{split}\n",
    "Var(X) &= Var(X_1 + X_2 + \\dots + X_n) \\\\\n",
    "    &= Var(X_1) + Var(X_2) + \\dots + Var(X_n) \\text{, Since } X_i \\text{ are independent} \\\\\n",
    "    &= nVar(X_i) = nE[ (X_i-E(X_i))^2 ] \\\\\n",
    "    &= n \\left[  P(X_i=1)(X_i-E(X_i))^2_{|x=1} + P(X_i=0)(X_i-E(X_i))^2_{|x=0}\\right] \\\\\n",
    "    &= n \\left[   p(1-p)^2 + (1-p)p^2\\right] \\\\\n",
    "    &= np(1-p)\n",
    "\\end{split}$$\n",
    "\n",
    "\n",
    "## 7.5 Exercise 2\n",
    "\n",
    "- Roll a fair dice. Let random variables\n",
    "    + X: the number on the dice\n",
    "    + Y: = 0 if X is even, = 1 if X is odd\n",
    "\n",
    "- Given Joint PMF Table, Find `cov(X,Y)`\n",
    "\n",
    "| Y\\X          | **X=1** | **X=2** | **X=3** | **X=4** | **X=5** | **X=6** |\n",
    "|--------------|---------|---------|---------|---------|---------|---------|\n",
    "| **Y=0**      | 0       | 1/6     | 0       | 1/6     | 0       | 1/6     |\n",
    "| **Y=1**      | 1/6     | 0       | 1/6     | 0       | 1/6     | 0       |\n",
    "\n",
    "#### Solve\n",
    "\n",
    "- Construct Joint PMF Table\n",
    "\n",
    "| Y\\X          | **X=1** | **X=2** | **X=3** | **X=4** | **X=5** | **X=6** | $P(Y = y_j)$ |\n",
    "|--------------|---------|---------|---------|---------|---------|---------|--------------|\n",
    "| **Y=0**      | 0       | 1/6     | 0       | 1/6     | 0       | 1/6     | 1/2          |\n",
    "| **Y=1**      | 1/6     | 0       | 1/6     | 0       | 1/6     | 0       | 1/2          |\n",
    "| $P(X = x_i)$ | 1/6     | 1/6     | 1/6     | 1/6     | 1/6     | 1/6     |              |\n",
    "\n",
    "\n",
    "- Expected values\n",
    "    + $E(X) = 1*\\frac{1}{6} + 2*\\frac{1}{6} + 3*\\frac{1}{6} + 4*\\frac{1}{6} + 5*\\frac{1}{6} + 6*\\frac{1}{6} = \\frac{7}{2}$\n",
    "    + $E(Y) = 0*\\frac{1}{2} + 1*\\frac{1}{2} = \\frac{1}{2}$ \n",
    "\n",
    "- Calculate $E(XY)$\n",
    "\n",
    "$$\\begin{split}\n",
    "E(XY) &= \\sum\\limits_i^m \\sum\\limits_j^n x_i y_j P(X=x_i \\cap Y=y_j) \\\\\n",
    "    &= (0)(1)(0) + (0)(2)(\\frac{1}{6}) + (0)(3)(0) + (0)(4)(\\frac{1}{6}) + (0)(5)(0) + (0)(6)(\\frac{1}{6}) + (1)(1)(\\frac{1}{6}) + (1)(2)(0) + (1)(3)(\\frac{1}{6}) + (1)(4)(0) + (1)(5)(\\frac{1}{6}) + (1)(6)(0) \\\\\n",
    "    &= 1.5\n",
    "\\end{split}$$\n",
    "\n",
    "- Calc cov(X,Y)\n",
    "    + $cov(X,Y) = E(XY) - E(X)E(Y) = 1.5 - 3.5*0.5 = -0.25$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Correlation\n",
    "- Another coefficient that can be used for showing some information about relation between two random variables.\n",
    "- correlation is strictly related to covariance\n",
    "\n",
    "## 8.1 Definition\n",
    "\n",
    "$$corr(X,Y) = \\frac{cov(X,Y)}{\\sqrt{Var(X)Var(Y)}}$$\n",
    "\n",
    "- $corr(X,Y) \\in [-1, 1]$\n",
    "- $corr(X,Y) = 0$ <=> `X,Y are uncorrelated`\n",
    "- `Positive Correlation` = corr(X,Y) closer to 1 = If 1 variable obtained large value, then the other most likely will also be large\n",
    "- `Negative Correlation` = corr(X,Y) closer to -1 = If 1 variable obtained large value, then the other most likely will be small\n",
    "\n",
    "## 8.2 Properties\n",
    "- Let $c, c_1, c_2$ = constant; X,Y = random variables\n",
    "    - $corr(cX,Y) = corr(X,Y)$, if `c > 0`\n",
    "    - $corr(X, c_1X + c_2) =  \\frac{c_1}{|c_1|} = \\begin{cases}   \n",
    "        1 \\text{, if } c_1>0 \\\\\n",
    "        -1 \\text{, if } c_1<0\n",
    "\\end{cases}$\n",
    "\n",
    "    - If $corr(X,Y) =  \\pm 1$ then $Y = c_1 X + c_2$\n",
    "        + The closer corr(X,Y) to $\\pm 1$, the more linear dependence between them\n",
    "\n",
    "- $corr(X,Y) = 0$ <=> $cov(X,Y) = 0$\n",
    "- if `X and Y are independent` then $corr(X,Y) = 0$, **Note**: The inverse is not true\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
